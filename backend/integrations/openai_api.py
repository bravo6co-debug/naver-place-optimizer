#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI GPT API í†µí•©
í‚¤ì›Œë“œ ìƒì„± ë° ì „ëµ ì œì•ˆ
"""

import os
import json
from typing import Optional, List, Dict
from openai import OpenAI


class OpenAIAPI:
    """OpenAI GPT API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.api_key) if self.api_key else None

    def generate_keywords(
        self,
        category: str,
        location: str,
        specialty: Optional[str] = None,
        modifier_examples: Optional[str] = None
    ) -> List[Dict]:
        """
        GPTë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ìƒì„±

        Args:
            category: ì—…ì¢…
            location: ì§€ì—­
            specialty: íŠ¹ì§•/ì „ë¬¸ë¶„ì•¼
            modifier_examples: ì—…ì¢…ë³„ ìˆ˜ì‹ì–´ ì˜ˆì‹œ

        Returns:
            ìƒì„±ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.client:
            return []

        prompt = self._build_keyword_prompt(category, location, specialty, modifier_examples)

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",  # âœ… GPT-4 full versionìœ¼ë¡œ ë³€ê²½ (ì •í™•ë„ í–¥ìƒ)
                messages=[
                    {"role": "system", "content": "You are a Naver Place SEO expert. Always respond in Korean with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,  # âœ… ì°½ì˜ì„± ì¦ê°€
                max_tokens=3500  # âœ… í† í° ì¦ê°€ (35ê°œ í‚¤ì›Œë“œ ìƒì„±)
            )

            content = response.choices[0].message.content
            keywords = self._parse_json_response(content)

            # âœ… 1ë‹¨ê³„: í˜•í¸ì—†ëŠ” í‚¤ì›Œë“œ í•„í„°ë§ (ìë™ ì œê±°)
            keywords = self._filter_bad_keywords(keywords, category, location)

            # âœ… 2ë‹¨ê³„: specialty í¬í•¨ ì—¬ë¶€ ê²€ì¦ (ê²½ê³  + ì œê±°)
            if specialty:
                keywords = self.validate_specialty_inclusion(keywords, specialty)

            return keywords

        except Exception as e:
            print(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _get_level2_examples(self, location: str, category: str, specialty_list: list) -> str:
        """Level 2 í‚¤ì›Œë“œ ì˜ˆì‹œ ìƒì„±"""
        base_location = location.split()[0] if " " in location else location

        if specialty_list:
            return f'"{base_location} {specialty_list[0]} ë§›ì§‘", "{base_location} {specialty_list[0]}"'
        else:
            return f'"{base_location} {category}"'

    def _get_level1_examples(self, location: str, category: str, specialty_list: list) -> str:
        """Level 1 í‚¤ì›Œë“œ ì˜ˆì‹œ ìƒì„± - Level 2ì™€ ì°¨ë³„í™”"""
        if specialty_list:
            # Level 1: ì§€ì—­ ì œê±°, specialty ì¤‘ì‹¬
            if len(specialty_list) > 1:
                return f'"{specialty_list[0]} ë§›ì§‘", "{specialty_list[1]}"'
            else:
                return f'"{specialty_list[0]} ë§›ì§‘", "{specialty_list[0]} {category}"'
        else:
            return f'"{category}", "{category} ì¶”ì²œ"'

    def _build_keyword_prompt(
        self,
        category: str,
        location: str,
        specialty: Optional[str],
        modifier_examples: Optional[str]
    ) -> str:
        """í‚¤ì›Œë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        # specialty íŒŒì‹±: ì»´ë§ˆë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ íŠ¹ì§• ì²˜ë¦¬
        specialty_list = []
        if specialty:
            specialty_list = [s.strip() for s in specialty.split(',') if s.strip()]

        # specialty í•„ìˆ˜ ê°•ì¡°
        specialty_emphasis = ""
        if specialty_list:
            if len(specialty_list) == 1:
                specialty_emphasis = f"""
ğŸ¯ **í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ (MANDATORY)**: {specialty_list[0]}
âš ï¸ **ì¤‘ìš”**: ëª¨ë“  í‚¤ì›Œë“œì— ì´ íŠ¹ì§•({specialty_list[0]})ì„ í•„ìˆ˜ë¡œ í¬í•¨í•˜ê±°ë‚˜, ì´ íŠ¹ì§•ê³¼ ê´€ë ¨ëœ ê²€ìƒ‰ ì˜ë„ë¥¼ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
- "{location} {specialty_list[0]} {category}" âœ“
- "{location} {specialty_list[0]} ì „ë¬¸ {category}" âœ“
- "{location} {category}" âœ— (íŠ¹ì§• ëˆ„ë½)
"""
            else:
                specialty_str = ', '.join(specialty_list)
                specialty_emphasis = f"""
ğŸ¯ **í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ (MANDATORY)**: {specialty_str}
âš ï¸ **ì¤‘ìš”**: ì´ ì—…ì²´ëŠ” ì—¬ëŸ¬ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ìƒì„± ì‹œ ë‹¤ìŒ ì „ëµì„ ì‚¬ìš©í•˜ì„¸ìš”:

1. **ê°œë³„ íŠ¹ì§• í™œìš©**: ê° íŠ¹ì§•ì„ ê°œë³„ì ìœ¼ë¡œ í‚¤ì›Œë“œì— í¬í•¨
   - ì˜ˆ: "{location} {specialty_list[0]} {category}"
   - ì˜ˆ: "{location} {specialty_list[1]} {category}"

2. **íŠ¹ì§• ì¡°í•© í™œìš©**: 2-3ê°œ íŠ¹ì§•ì„ ì¡°í•©í•˜ì—¬ ì°¨ë³„í™”
   - ì˜ˆ: "{location} {specialty_list[0]} {specialty_list[1]} {category}"
   - ì˜ˆ: "{location} {' '.join(specialty_list[:2])} {category}"

3. **ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„**: ì‹¤ì œ ê²€ìƒ‰ì–´ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ
   - ì˜ˆ: "{location} {specialty_list[0]}ë„ ë˜ê³  {specialty_list[1]}ë„ ë˜ëŠ” {category}"

âš ï¸ **í•„ìˆ˜**: ê° í‚¤ì›Œë“œëŠ” ìµœì†Œ 1ê°œ ì´ìƒì˜ íŠ¹ì§•ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
        else:
            specialty_emphasis = """
âš ï¸ **íŠ¹ì§•ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.** ì—…ì¢…ì˜ ì¼ë°˜ì ì¸ ì°¨ë³„í™” ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.
"""

        specialty_str = ', '.join(specialty_list) if specialty_list else "ì—†ìŒ"

        prompt = f"""ë‹¹ì‹ ì€ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê²€ìƒ‰ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
**ì‹¤ì œ ì‚¬ëŒë“¤ì´ ê²€ìƒ‰í•˜ëŠ”** í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.

**ì‚¬ìš©ì ì…ë ¥:**
- category: {category}
- location: {location}
- specialty: {specialty_str}

{specialty_emphasis}

**ì¶œë ¥ í˜•ì‹**: JSON ê°ì²´ (ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSON)
í‚¤: `longtail_keywords`, `mid_keywords`, `category_keywords`, `top_keywords`

---

## âœ… ì¢‹ì€ í‚¤ì›Œë“œ (GOOD - ì´ë ‡ê²Œ ìƒì„±í•˜ì„¸ìš”!)

**ë¡±í…Œì¼ (ìì—°ìŠ¤ëŸ¬ìš´ ê²€ìƒ‰ì–´):**
- âœ… "ê°•ë‚¨ì—­ ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ {specialty} ì¹´í˜"
- âœ… "ê°•ë‚¨ ì¡°ìš©í•œ ê³µë¶€ ì¹´í˜ {specialty} ë˜ëŠ” ê³³"
- âœ… "ì‹ ë…¼í˜„ì—­ ê·¼ì²˜ {specialty} ë§›ì§‘ ì¹´í˜ ì¶”ì²œ"
- âœ… "ê°•ë‚¨ì—­ 3ë²ˆì¶œêµ¬ {specialty} ì¹´í˜ ì–´ë””ìˆì–´ìš”"

**ë‹ˆì¹˜ (ì‹¤ì „ ì¡°í•©):**
- âœ… "ê°•ë‚¨ì—­ {specialty} ì¹´í˜"
- âœ… "ê°•ë‚¨ {specialty} ì¹´í˜ ì¶”ì²œ"
- âœ… "ì‹ ë…¼í˜„ {specialty} ë§›ì§‘"

---

## âŒ ë‚˜ìœ í‚¤ì›Œë“œ (BAD - ì ˆëŒ€ ìƒì„± ê¸ˆì§€!)

**ì¼ë°˜ì ì´ê³  í˜•í¸ì—†ëŠ” í‚¤ì›Œë“œ:**
- âŒ "{location} ìµœê³  {category}" (ë„ˆë¬´ ì¶”ìƒì )
- âŒ "{location} í”„ë¦¬ë¯¸ì—„ {category}" (ì˜ë¯¸ ì—†ìŒ)
- âŒ "{location} ê³ ê¸‰ {category}" (ì‹¤ì œ ê²€ìƒ‰ ì•ˆ í•¨)
- âŒ "{location} ì „ë¬¸ {category}" (ë„ˆë¬´ ì¼ë°˜ì )
- âŒ "{location} ìœ ëª…í•œ {category}" (êµ¬ì²´ì„± ì—†ìŒ)

**specialty ì—†ëŠ” í‚¤ì›Œë“œ:**
- âŒ "{location} {category}" (specialty ëˆ„ë½)
- âŒ "{location} {category} ì¶”ì²œ" (specialty ì—†ìŒ)

---

## ğŸ“‹ ìƒì„± ìš”êµ¬ì‚¬í•­

**longtail_keywords** (ì •í™•íˆ 15ê°œ):
- ì‹¤ì œ ì‚¬ëŒë“¤ì´ ê²€ìƒ‰í•˜ëŠ” **ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥**
- ëª©ì  í¬í•¨ (ë°ì´íŠ¸, ê³µë¶€, íšŒì˜, í˜¼ì, ê°€ì¡± ë“±)
- ì„¸ë¶€ ì§€ì—­ ì‚¬ìš© (ê°•ë‚¨ì—­, ì‹ ë…¼í˜„ì—­, ì••êµ¬ì • ë“±)
- ì¡°ì‚¬ í¬í•¨ ("-í•˜ê¸° ì¢‹ì€", "-ë˜ëŠ” ê³³", "ì–´ë””ìˆì–´ìš”" ë“±)
- **specialty í•„ìˆ˜ í¬í•¨**

**ì˜ˆì‹œ:**
- "{location}ì—­ ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ {specialty} {category}"
- "{location} ì¡°ìš©í•œ {specialty} {category} ì¶”ì²œ"
- "{location}ì—­ ê·¼ì²˜ {specialty} ë§›ì§‘ {category} ì–´ë””?"

**mid_keywords** (ì •í™•íˆ 10ê°œ):
- ì¤‘ê°„ ê¸¸ì´ ì‹¤ì „ í‚¤ì›Œë“œ
- ì„¸ë¶€ ì§€ì—­ + specialty + category ì¡°í•©
- **specialty í•„ìˆ˜ í¬í•¨**

**ì˜ˆì‹œ:**
- "{location}ì—­ {specialty} {category}"
- "{location} {specialty} ë§›ì§‘"
- "{location} {specialty} {category} ì¶”ì²œ"

**category_keywords** (ì •í™•íˆ 7ê°œ):
- ì—…ì¢… ê´€ë ¨ í‚¤ì›Œë“œ
- specialty í¬í•¨í•œ ì—…ì¢… ì¡°í•©
- ë™ì˜ì–´, í•˜ìœ„ ì—…ì¢…

**ì˜ˆì‹œ:**
- "{specialty} {category}"
- "{specialty} ì „ë¬¸ {category}"
- "{category} (ë™ì˜ì–´)"

**top_keywords** (ì •í™•íˆ 3ê°œ):
- ê´‘ë²”ìœ„í•œ ìƒìœ„ í‚¤ì›Œë“œ
- specialty í¬í•¨ ê°€ëŠ¥ (ì„ íƒ)

**ì˜ˆì‹œ:**
- "{category}"
- "{specialty} {category}"
- "ê´‘ì—­ì§€ì—­ {category}"

---

## ğŸ¯ í•µì‹¬ ê·œì¹™

1. **specialty í•„ìˆ˜ í¬í•¨** (longtail, mid, categoryì— íŠ¹íˆ ì¤‘ìš”)
2. **ì‹¤ì œ ê²€ìƒ‰ì–´** ìƒì„± ("ìµœê³ ", "í”„ë¦¬ë¯¸ì—„" ê°™ì€ ì“°ë ˆê¸° ê¸ˆì§€)
3. **ì„¸ë¶€ ì§€ì—­ ì‚¬ìš©** (ê°•ë‚¨ì—­, ì‹ ë…¼í˜„ì—­, ì••êµ¬ì • ë“±)
4. **ëª©ì  í‚¤ì›Œë“œ** í¬í•¨ (ë°ì´íŠ¸, ê³µë¶€, íšŒì˜ ë“±)
5. **ìì—°ìŠ¤ëŸ¬ìš´ ì¡°ì‚¬** í¬í•¨ (-í•˜ê¸° ì¢‹ì€, -ë˜ëŠ” ê³³ ë“±)
6. **ì´ 35ê°œ ì •í™•íˆ** ìƒì„± (15+10+7+3)

---

**ì¶œë ¥ ì˜ˆì‹œ** (category=ì¹´í˜, location=ì„œìš¸ ê°•ë‚¨êµ¬, specialty=ë¸ŒëŸ°ì¹˜, ì• ê²¬ë™ë°˜):
{{
  "longtail_keywords": [
    "ê°•ë‚¨ì—­ ë°ì´íŠ¸í•˜ê¸° ì¢‹ì€ ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ê°•ë‚¨ ì¡°ìš©í•œ ê³µë¶€ ì¹´í˜ ì• ê²¬ë™ë°˜ ë˜ëŠ” ê³³",
    "ì‹ ë…¼í˜„ì—­ ê·¼ì²˜ ë¸ŒëŸ°ì¹˜ ë§›ì§‘ ì¹´í˜ ì¶”ì²œ",
    "ê°•ë‚¨ì—­ 3ë²ˆì¶œêµ¬ ì• ê²¬ë™ë°˜ ì¹´í˜ ì–´ë””ìˆì–´ìš”",
    "ì••êµ¬ì • ë¸ŒëŸ°ì¹˜ ë§›ìˆëŠ” ê°•ì•„ì§€ ë™ë°˜ ì¹´í˜",
    "ê°•ë‚¨ í˜¼ì ê°€ê¸° ì¢‹ì€ ë¸ŒëŸ°ì¹˜ ì¹´í˜ ì• ê²¬ ê°€ëŠ¥",
    "ê°•ë‚¨ì—­ ì£¼ì°¨ ê°€ëŠ¥í•œ ì• ê²¬ë™ë°˜ ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ì‹ ë…¼í˜„ ë°˜ë ¤ê²¬ ë™ë°˜ ë¸ŒëŸ°ì¹˜ ë§›ì§‘ ì¶”ì²œ",
    "ê°•ë‚¨ ì• ê²¬ ì¹´í˜ ë¸ŒëŸ°ì¹˜ í•˜ê¸° ì¢‹ì€ ê³³",
    "ê°•ë‚¨ì—­ ê·¼ì²˜ ê°•ì•„ì§€ ë°ë¦¬ê³  ê°ˆ ìˆ˜ ìˆëŠ” ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ì••êµ¬ì •ë¡œë°ì˜¤ ë¸ŒëŸ°ì¹˜ ì¹´í˜ ì• ê²¬ë™ë°˜ ë˜ë‚˜ìš”",
    "ê°•ë‚¨ ë¸ŒëŸ°ì¹˜ ë§›ì§‘ ê°•ì•„ì§€ ë™ë°˜ ê°€ëŠ¥í•œ ê³³",
    "ì‹ ë…¼í˜„ì—­ ë„ë³´ 5ë¶„ ì• ê²¬ë™ë°˜ ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ê°•ë‚¨ ì¸ìŠ¤íƒ€ ê°ì„± ë¸ŒëŸ°ì¹˜ ì¹´í˜ ì• ê²¬ ê°€ëŠ¥",
    "ê°•ë‚¨ì—­ í…Œë¼ìŠ¤ ìˆëŠ” ì• ê²¬ë™ë°˜ ë¸ŒëŸ°ì¹˜ ì¹´í˜"
  ],
  "mid_keywords": [
    "ê°•ë‚¨ì—­ ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ê°•ë‚¨ ì• ê²¬ë™ë°˜ ì¹´í˜",
    "ì‹ ë…¼í˜„ ë¸ŒëŸ°ì¹˜ ë§›ì§‘",
    "ê°•ë‚¨ì—­ ì• ê²¬ ì¹´í˜",
    "ì••êµ¬ì • ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ê°•ë‚¨ ê°•ì•„ì§€ ë™ë°˜ ì¹´í˜",
    "ê°•ë‚¨ì—­ ë¸ŒëŸ°ì¹˜ ë§›ì§‘",
    "ì‹ ë…¼í˜„ ì• ê²¬ë™ë°˜ ì¹´í˜",
    "ê°•ë‚¨ ë¸ŒëŸ°ì¹˜ ì• ê²¬ ì¹´í˜",
    "ì••êµ¬ì • ì• ê²¬ë™ë°˜ ë¸ŒëŸ°ì¹˜"
  ],
  "category_keywords": [
    "ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ì• ê²¬ë™ë°˜ ì¹´í˜",
    "ê°•ì•„ì§€ ì¹´í˜",
    "ë°˜ë ¤ê²¬ ì¹´í˜",
    "í«í”„ë Œë“¤ë¦¬ ì¹´í˜",
    "ë¸ŒëŸ°ì¹˜ ë§›ì§‘",
    "ì»¤í”¼ìˆ"
  ],
  "top_keywords": [
    "ì¹´í˜",
    "ë¸ŒëŸ°ì¹˜",
    "ì• ê²¬ ì¹´í˜"
  ]
}}

**ì¤‘ìš”**: ë°˜ë“œì‹œ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì£¼ì„ ì—†ì´!"""

        return prompt

    def _parse_json_response(self, content: str) -> List[Dict]:
        """GPT ì‘ë‹µì—ì„œ JSON íŒŒì‹± (ìƒˆ í˜•ì‹ â†’ ê¸°ì¡´ level í˜•ì‹ ë³€í™˜)"""
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            data = json.loads(content.strip())

            # ìƒˆ í˜•ì‹ì¸ì§€ í™•ì¸ (longtail_keywords, mid_keywords ë“±ì˜ í‚¤ ì¡´ì¬)
            if isinstance(data, dict) and "longtail_keywords" in data:
                # ìƒˆ í˜•ì‹ â†’ ê¸°ì¡´ level í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                keywords = []

                # longtail_keywords â†’ Level 5
                for kw in data.get("longtail_keywords", []):
                    keywords.append({"keyword": kw, "level": 5, "reason": "ë¡±í…Œì¼ ê²€ìƒ‰ì–´"})

                # mid_keywords â†’ Level 4
                for kw in data.get("mid_keywords", []):
                    keywords.append({"keyword": kw, "level": 4, "reason": "ë‹ˆì¹˜ ê²€ìƒ‰ì–´"})

                # category_keywords â†’ Level 3
                for kw in data.get("category_keywords", []):
                    keywords.append({"keyword": kw, "level": 3, "reason": "ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ì–´"})

                # top_keywords â†’ Level 2, Level 1ë¡œ ë¶„í• 
                top_kws = data.get("top_keywords", [])
                if len(top_kws) >= 2:
                    keywords.append({"keyword": top_kws[0], "level": 2, "reason": "ìƒìœ„ ê²€ìƒ‰ì–´"})
                    keywords.append({"keyword": top_kws[1], "level": 1, "reason": "ìµœìƒìœ„ ê²€ìƒ‰ì–´"})
                elif len(top_kws) == 1:
                    keywords.append({"keyword": top_kws[0], "level": 2, "reason": "ìƒìœ„ ê²€ìƒ‰ì–´"})

                return keywords

            # ê¸°ì¡´ í˜•ì‹ (list of dicts with level)
            return data

        except Exception as e:
            print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def generate_related_keywords(
        self,
        category: str,
        specialty: Optional[str] = None
    ) -> Dict[str, List[str]]:
        """
        GPTë¥¼ ì‚¬ìš©í•œ ì—°ê´€ í‚¤ì›Œë“œ ìƒì„± (ì¡°í•©í•˜ì§€ ì•Šê³  ì—°ê´€ì–´ë§Œ)

        Args:
            category: ì—…ì¢… (ì˜ˆ: "ì¹´í˜", "ë³‘ì›")
            specialty: íŠ¹ì§•/ì „ë¬¸ë¶„ì•¼ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: "ë¸ŒëŸ°ì¹˜, ì• ê²¬ë™ë°˜")

        Returns:
            ì—°ê´€ í‚¤ì›Œë“œ ë”•ì…”ë„ˆë¦¬
            {
                "category_related": ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"],
                "specialty1_related": ["ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ì•„ì¹¨ì‹ì‚¬", "ëª¨ë‹ì‹ì‚¬", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜ë©”ë‰´"],
                "specialty2_related": ["ë°˜ë ¤ë™ë¬¼", "ê°•ì•„ì§€ë™ë°˜", "í«í”„ë Œë“¤ë¦¬", "ì• ê²¬ì¹´í˜", "ë°˜ë ¤ê²¬"]
            }
        """
        if not self.client:
            return {}

        specialty_list = []
        if specialty:
            specialty_list = [s.strip() for s in specialty.split(',') if s.strip()]

        specialty_str = ', '.join(specialty_list) if specialty_list else "ì—†ìŒ"

        prompt = f"""ë‹¹ì‹ ì€ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê²€ìƒ‰ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì—…ì¢…ê³¼ íŠ¹ì„±ì— ëŒ€í•œ **ì—°ê´€ í‚¤ì›Œë“œ**ë§Œ ìƒì„±í•˜ì„¸ìš”. (ì¡°í•©í•˜ì§€ ë§ ê²ƒ!)

**ì…ë ¥:**
- category: {category}
- specialty: {specialty_str}

**ì¶œë ¥ í˜•ì‹**: JSON ê°ì²´ (ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSON)

**ê·œì¹™:**
1. categoryì— ëŒ€í•œ ì—°ê´€ í‚¤ì›Œë“œ 5ê°œ ìƒì„± â†’ "category_related" í‚¤
   - ë™ì˜ì–´, í•˜ìœ„ ì—…ì¢…, ìœ ì‚¬ ì—…ì¢… í¬í•¨
   - ì˜ˆ: category="ì¹´í˜" â†’ ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"]

2. specialtyê°€ ìˆìœ¼ë©´ ê° íŠ¹ì„±ë§ˆë‹¤ ì—°ê´€ í‚¤ì›Œë“œ 5ê°œì”© ìƒì„± â†’ "specialty1_related", "specialty2_related" ë“±ì˜ í‚¤
   - ë™ì˜ì–´, ê´€ë ¨ í‘œí˜„, ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ í¬í•¨
   - ì˜ˆ: specialty="ë¸ŒëŸ°ì¹˜" â†’ ["ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ì•„ì¹¨ì‹ì‚¬", "ëª¨ë‹ì‹ì‚¬", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜ë©”ë‰´"]
   - ì˜ˆ: specialty="ì• ê²¬ë™ë°˜" â†’ ["ë°˜ë ¤ë™ë¬¼", "ê°•ì•„ì§€ë™ë°˜", "í«í”„ë Œë“¤ë¦¬", "ì• ê²¬ì¹´í˜", "ë°˜ë ¤ê²¬"]

3. **ì¤‘ìš”**: ì¡°í•©í•˜ì§€ ë§ê³  ë‹¨ì¼ í‚¤ì›Œë“œë§Œ ìƒì„±í•  ê²ƒ!
   - âœ… Good: "ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ê°•ì•„ì§€ë™ë°˜"
   - âŒ Bad: "ë¸ŒëŸ°ì¹˜ ê°•ì•„ì§€ë™ë°˜ ì¹´í˜", "í™ëŒ€ ë¸ŒëŸ°ì¹˜"

**ì¶œë ¥ ì˜ˆì‹œ 1** (category=ì¹´í˜, specialty=ë¸ŒëŸ°ì¹˜, ì• ê²¬ë™ë°˜):
{{
  "category_related": ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"],
  "specialty1_related": ["ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ì•„ì¹¨ì‹ì‚¬", "ëª¨ë‹ì‹ì‚¬", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜ë©”ë‰´"],
  "specialty2_related": ["ë°˜ë ¤ë™ë¬¼", "ê°•ì•„ì§€ë™ë°˜", "í«í”„ë Œë“¤ë¦¬", "ì• ê²¬ì¹´í˜", "ë°˜ë ¤ê²¬ë™ë°˜"]
}}

**ì¶œë ¥ ì˜ˆì‹œ 2** (category=ë³‘ì›, specialty=ì•ˆê³¼):
{{
  "category_related": ["ì˜ë£Œê¸°ê´€", "ì¢…í•©ë³‘ì›", "í´ë¦¬ë‹‰", "ì˜ì›", "ì§„ë£Œì†Œ"],
  "specialty1_related": ["ì•ˆê³¼ì˜ì›", "ëˆˆë³‘ì›", "ì‹œë ¥êµì •", "ë¼ì‹", "ì•ˆê³¼ì§„ë£Œ"]
}}

**ì¶œë ¥ ì˜ˆì‹œ 3** (category=ì¹´í˜, specialty ì—†ìŒ):
{{
  "category_related": ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"]
}}

ì´ì œ ì…ë ¥ëœ ì •ë³´ë¡œ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a Naver Place SEO expert. Always respond in Korean with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )

            content = response.choices[0].message.content

            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            related_keywords = json.loads(content.strip())
            return related_keywords

        except Exception as e:
            print(f"ì—°ê´€ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def _filter_bad_keywords(
        self,
        keywords: List[Dict],
        category: str,
        location: str
    ) -> List[Dict]:
        """
        í˜•í¸ì—†ëŠ” í‚¤ì›Œë“œ íŒ¨í„´ ìë™ ì œê±°

        Args:
            keywords: ìƒì„±ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            category: ì—…ì¢…
            location: ì§€ì—­

        Returns:
            í•„í„°ë§ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        # ì“°ë ˆê¸° ë‹¨ì–´ ëª©ë¡ (ì‹¤ì œë¡œ ì‚¬ëŒë“¤ì´ ê²€ìƒ‰ ì•ˆ í•˜ëŠ” ë‹¨ì–´ë“¤)
        BAD_WORDS = [
            "ìµœê³ ", "í”„ë¦¬ë¯¸ì—„", "ê³ ê¸‰", "ë² í…Œë‘", "ìˆ™ë ¨",
            "ì „ë¬¸ê°€", "ëª…ì¸", "ë‹¬ì¸", "ì¥ì¸"
        ]

        # ë„ˆë¬´ ì¼ë°˜ì ì¸ íŒ¨í„´
        BAD_PATTERNS = [
            f"{location} {category}",  # specialty ì—†ëŠ” ê¸°ë³¸ ì¡°í•©
            f"{location} ìœ ëª…í•œ {category}",
            f"{location} ì¸ê¸° {category}",
        ]

        filtered = []
        removed_count = 0

        for kw in keywords:
            keyword_text = kw.get('keyword', '')
            level = kw.get('level', 5)

            # ì“°ë ˆê¸° ë‹¨ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
            has_bad_word = any(bad_word in keyword_text for bad_word in BAD_WORDS)

            # ë‚˜ìœ íŒ¨í„´ ì •í™•íˆ ì¼ì¹˜ í™•ì¸
            is_bad_pattern = keyword_text in BAD_PATTERNS

            # Level 3-5ëŠ” specialty í•„ìˆ˜ (specialty ì—†ìœ¼ë©´ ë„ˆë¬´ ì¼ë°˜ì )
            # Level 1-2ëŠ” ê´‘ë²”ìœ„í•´ë„ OK
            is_too_generic = (level >= 3) and (keyword_text == f"{location} {category}" or keyword_text == f"{location} {category} ì¶”ì²œ")

            if has_bad_word:
                print(f"âŒ [í•„í„°ë§] '{keyword_text}' - ì“°ë ˆê¸° ë‹¨ì–´ í¬í•¨")
                removed_count += 1
                continue

            if is_bad_pattern:
                print(f"âŒ [í•„í„°ë§] '{keyword_text}' - ë‚˜ìœ íŒ¨í„´")
                removed_count += 1
                continue

            if is_too_generic:
                print(f"âŒ [í•„í„°ë§] '{keyword_text}' - ë„ˆë¬´ ì¼ë°˜ì  (Level {level})")
                removed_count += 1
                continue

            # í†µê³¼í•œ í‚¤ì›Œë“œë§Œ ì¶”ê°€
            filtered.append(kw)

        if removed_count > 0:
            print(f"âœ… ì´ {removed_count}ê°œ í˜•í¸ì—†ëŠ” í‚¤ì›Œë“œ ì œê±°ë¨")

        return filtered

    def validate_specialty_inclusion(
        self,
        keywords: List[Dict],
        specialty: Optional[str]
    ) -> List[Dict]:
        """
        specialtyê°€ ì œê³µëœ ê²½ìš° í‚¤ì›Œë“œì— í¬í•¨ ì—¬ë¶€ ê²€ì¦ (ë‹¨ê³„ì  ê¸°ì¤€)

        Args:
            keywords: ìƒì„±ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            specialty: íŠ¹ì§•/ì „ë¬¸ë¶„ì•¼

        Returns:
            ê²€ì¦ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ê²½ê³  í¬í•¨)
        """
        if not specialty:
            return keywords

        specialty_list = [s.strip() for s in specialty.split(',') if s.strip()]
        if not specialty_list:
            return keywords

        # Levelë³„ specialty í¬í•¨ ì¹´ìš´íŠ¸
        level_stats = {1: {"total": 0, "with_specialty": 0},
                       2: {"total": 0, "with_specialty": 0},
                       3: {"total": 0, "with_specialty": 0},
                       4: {"total": 0, "with_specialty": 0},
                       5: {"total": 0, "with_specialty": 0}}

        validated = []
        for kw in keywords:
            keyword_text = kw.get('keyword', '')
            level = kw.get('level', 5)

            # specialty í¬í•¨ ì—¬ë¶€ í™•ì¸
            has_specialty = any(spec.lower() in keyword_text.lower() for spec in specialty_list)

            level_stats[level]["total"] += 1
            if has_specialty:
                level_stats[level]["with_specialty"] += 1

            # Level 1-2ëŠ” 100% í•„ìˆ˜
            if not has_specialty and level <= 2:
                print(f"âš ï¸ [CRITICAL] Level {level} í‚¤ì›Œë“œ '{keyword_text}'ì— íŠ¹ì§•({', '.join(specialty_list)}) ëˆ„ë½ (í•„ìˆ˜!)")

            validated.append(kw)

        # Levelë³„ í¬í•¨ë¥  ê²€ì¦
        thresholds = {1: 1.0, 2: 1.0, 3: 0.8, 4: 0.7, 5: 0.6}
        for level, stats in level_stats.items():
            if stats["total"] > 0:
                rate = stats["with_specialty"] / stats["total"]
                threshold = thresholds[level]
                if rate < threshold:
                    print(f"âš ï¸ Level {level} specialty í¬í•¨ë¥ : {rate:.1%} (ëª©í‘œ: {threshold:.0%}) - {stats['with_specialty']}/{stats['total']}ê°œ")

        return validated
