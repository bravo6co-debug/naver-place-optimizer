#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenAI GPT API í†µí•©
í‚¤ì›Œë“œ ìƒì„± ë° ì „ëµ ì œì•ˆ
"""

import os
import json
from typing import Optional, List, Dict
from openai import OpenAI


class OpenAIAPI:
    """OpenAI GPT API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.client = OpenAI(api_key=self.api_key) if self.api_key else None

    def generate_keywords(
        self,
        category: str,
        location: str,
        specialty: Optional[str] = None,
        modifier_examples: Optional[str] = None
    ) -> List[Dict]:
        """
        GPTë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ìƒì„±

        Args:
            category: ì—…ì¢…
            location: ì§€ì—­
            specialty: íŠ¹ì§•/ì „ë¬¸ë¶„ì•¼
            modifier_examples: ì—…ì¢…ë³„ ìˆ˜ì‹ì–´ ì˜ˆì‹œ

        Returns:
            ìƒì„±ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.client:
            return []

        prompt = self._build_keyword_prompt(category, location, specialty, modifier_examples)

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a Naver Place SEO expert. Always respond in Korean with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )

            content = response.choices[0].message.content
            keywords = self._parse_json_response(content)

            # specialty í¬í•¨ ì—¬ë¶€ ê²€ì¦ (ê²½ê³ ë§Œ í‘œì‹œ, í‚¤ì›Œë“œëŠ” ìœ ì§€)
            if specialty:
                keywords = self.validate_specialty_inclusion(keywords, specialty)

            return keywords

        except Exception as e:
            print(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _get_level2_examples(self, location: str, category: str, specialty_list: list) -> str:
        """Level 2 í‚¤ì›Œë“œ ì˜ˆì‹œ ìƒì„±"""
        base_location = location.split()[0] if " " in location else location

        if specialty_list:
            return f'"{base_location} {specialty_list[0]} ë§›ì§‘", "{base_location} {specialty_list[0]}"'
        else:
            return f'"{base_location} {category}"'

    def _get_level1_examples(self, location: str, category: str, specialty_list: list) -> str:
        """Level 1 í‚¤ì›Œë“œ ì˜ˆì‹œ ìƒì„± - Level 2ì™€ ì°¨ë³„í™”"""
        if specialty_list:
            # Level 1: ì§€ì—­ ì œê±°, specialty ì¤‘ì‹¬
            if len(specialty_list) > 1:
                return f'"{specialty_list[0]} ë§›ì§‘", "{specialty_list[1]}"'
            else:
                return f'"{specialty_list[0]} ë§›ì§‘", "{specialty_list[0]} {category}"'
        else:
            return f'"{category}", "{category} ì¶”ì²œ"'

    def _build_keyword_prompt(
        self,
        category: str,
        location: str,
        specialty: Optional[str],
        modifier_examples: Optional[str]
    ) -> str:
        """í‚¤ì›Œë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""

        # specialty íŒŒì‹±: ì»´ë§ˆë¡œ êµ¬ë¶„ëœ ì—¬ëŸ¬ íŠ¹ì§• ì²˜ë¦¬
        specialty_list = []
        if specialty:
            specialty_list = [s.strip() for s in specialty.split(',') if s.strip()]

        # specialty í•„ìˆ˜ ê°•ì¡°
        specialty_emphasis = ""
        if specialty_list:
            if len(specialty_list) == 1:
                specialty_emphasis = f"""
ğŸ¯ **í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ (MANDATORY)**: {specialty_list[0]}
âš ï¸ **ì¤‘ìš”**: ëª¨ë“  í‚¤ì›Œë“œì— ì´ íŠ¹ì§•({specialty_list[0]})ì„ í•„ìˆ˜ë¡œ í¬í•¨í•˜ê±°ë‚˜, ì´ íŠ¹ì§•ê³¼ ê´€ë ¨ëœ ê²€ìƒ‰ ì˜ë„ë¥¼ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆì‹œ:
- "{location} {specialty_list[0]} {category}" âœ“
- "{location} {specialty_list[0]} ì „ë¬¸ {category}" âœ“
- "{location} {category}" âœ— (íŠ¹ì§• ëˆ„ë½)
"""
            else:
                specialty_str = ', '.join(specialty_list)
                specialty_emphasis = f"""
ğŸ¯ **í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ (MANDATORY)**: {specialty_str}
âš ï¸ **ì¤‘ìš”**: ì´ ì—…ì²´ëŠ” ì—¬ëŸ¬ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œ ìƒì„± ì‹œ ë‹¤ìŒ ì „ëµì„ ì‚¬ìš©í•˜ì„¸ìš”:

1. **ê°œë³„ íŠ¹ì§• í™œìš©**: ê° íŠ¹ì§•ì„ ê°œë³„ì ìœ¼ë¡œ í‚¤ì›Œë“œì— í¬í•¨
   - ì˜ˆ: "{location} {specialty_list[0]} {category}"
   - ì˜ˆ: "{location} {specialty_list[1]} {category}"

2. **íŠ¹ì§• ì¡°í•© í™œìš©**: 2-3ê°œ íŠ¹ì§•ì„ ì¡°í•©í•˜ì—¬ ì°¨ë³„í™”
   - ì˜ˆ: "{location} {specialty_list[0]} {specialty_list[1]} {category}"
   - ì˜ˆ: "{location} {' '.join(specialty_list[:2])} {category}"

3. **ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„**: ì‹¤ì œ ê²€ìƒ‰ì–´ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ
   - ì˜ˆ: "{location} {specialty_list[0]}ë„ ë˜ê³  {specialty_list[1]}ë„ ë˜ëŠ” {category}"

âš ï¸ **í•„ìˆ˜**: ê° í‚¤ì›Œë“œëŠ” ìµœì†Œ 1ê°œ ì´ìƒì˜ íŠ¹ì§•ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
"""
        else:
            specialty_emphasis = """
âš ï¸ **íŠ¹ì§•ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.** ì—…ì¢…ì˜ ì¼ë°˜ì ì¸ ì°¨ë³„í™” ìš”ì†Œë¥¼ ê³ ë ¤í•˜ì—¬ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”.
"""

        specialty_str = ', '.join(specialty_list) if specialty_list else "ì—†ìŒ"

        prompt = f"""ë‹¹ì‹ ì€ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê²€ìƒ‰ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì…ë ¥ì— ë§ëŠ” **í˜„ì‹¤ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´** í‚¤ì›Œë“œ ëª©ë¡ì„ ìƒì„±í•˜ì„¸ìš”.

**ì‚¬ìš©ì ì…ë ¥:**
- category: {category}
- location: {location}
- specialty: {specialty_str}

**ì¶œë ¥ í˜•ì‹**: JSON ê°ì²´ (ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSON). í‚¤ëŠ” `longtail_keywords`, `mid_keywords`, `category_keywords`, `top_keywords`ì˜ 4ê°€ì§€ì´ë©°, ê° ê°’ì€ í•´ë‹¹ ìœ í˜•ì˜ í‚¤ì›Œë“œ ë¬¸ìì—´ë“¤ì„ ìš”ì†Œë¡œ ê°–ëŠ” ë°°ì—´ì…ë‹ˆë‹¤.

**longtail_keywords** (5~10ê°œ): êµ¬ì²´ì ì¸ **í•œêµ­ì–´ ë¡±í…Œì¼ ê²€ìƒ‰ì–´**ë¡œ, ì„¸ë¶€ ì§€ì—­ëª…, ëª©ì ì´ë‚˜ ì§ˆë¬¸ í˜•íƒœ, ì¡°ì‚¬ê°€ í¬í•¨ëœ **ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥**ì…ë‹ˆë‹¤. êµ¬ì–´ì²´ í‘œí˜„ë„ í—ˆìš©ë©ë‹ˆë‹¤. **ê° í‚¤ì›Œë“œì—ëŠ” specialty ëª©ë¡ ì¤‘ ìµœì†Œ í•˜ë‚˜ì˜ ìš”ì†Œë¥¼ í¬í•¨**í•´ì•¼ í•˜ë©° (ë™ì˜ì–´ë‚˜ ìœ ì‚¬ í‘œí˜„ìœ¼ë¡œ ë³€í˜• ê°€ëŠ¥), ëª…ì‚¬ë§Œ ë‚˜ì—´í•˜ëŠ” í˜•íƒœëŠ” í”¼í•´ì£¼ì„¸ìš”.
  *ì˜ˆì‹œ*: "í™ëŒ€ ì• ê²¬ë™ë°˜ ë¸ŒëŸ°ì¹˜ ì¹´í˜ ì¶”ì²œ", "ê°•ë‚¨ì—­ì—ì„œ ìˆ˜ë©´ë‚´ì‹œê²½ ì˜í•˜ëŠ” ë‚´ê³¼ ì–´ë””ì¸ê°€ìš”"

**mid_keywords** (3~5ê°œ): **ì—…ì¢…+ì§€ì—­** ë˜ëŠ” **ì§€ì—­+íŠ¹ì„±** ë“±ì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ í‚¤ì›Œë“œì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ê²€ìƒ‰ì–´ í˜•íƒœë¡œ **ì§§ê²Œ** í‘œí˜„í•˜ë˜, ì˜ë¯¸ ì „ë‹¬ì„ ìœ„í•´ í•„ìš”í•œ ê²½ìš° ì¼ë¶€ ì¡°ì‚¬ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° í‚¤ì›Œë“œ ì—­ì‹œ **specialty ì¤‘ í•˜ë‚˜ ì´ìƒì„ í¬í•¨**í•´ì•¼ í•©ë‹ˆë‹¤.
  *ì˜ˆì‹œ*: "í™ëŒ€ ì• ê²¬ë™ë°˜ ì¹´í˜", "ê°•ë‚¨ì—­ ìˆ˜ë©´ë‚´ì‹œê²½ ë‚´ê³¼"

**category_keywords** (2~3ê°œ): ì…ë ¥ëœ ì—…ì¢…ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ **ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ**ì…ë‹ˆë‹¤. í•´ë‹¹ ì—…ì¢…ì˜ í”í•œ **ë™ì˜ì–´**ë‚˜ **í•˜ìœ„ ì—…ì¢…**(íŠ¹ì • íŠ¹ì„±ì„ í¬í•¨í•œ ì—…ì¢…)ì„ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ëŠ¥í•˜ë©´ specialtyì— í•´ë‹¹í•˜ëŠ” ìš”ì†Œë¥¼ í¬í•¨í•œ ì¡°í•©ì„ ì‚¬ìš©í•˜ì„¸ìš”.
  *ì˜ˆì‹œ*: ì¹´í˜ ì—…ì¢…ì˜ ê²½ìš° ["ë¸ŒëŸ°ì¹˜ ì¹´í˜", "ì• ê²¬ë™ë°˜ ì¹´í˜"] *(ë™ì¼ ì—…ì¢…ì˜ ë™ì˜ì–´ "ì»¤í”¼ìˆ" ë“±ë„ ê³ ë ¤ ê°€ëŠ¥)*

**top_keywords** (1~2ê°œ): ê°€ì¥ ë‹¨ìˆœí•˜ê³  í•µì‹¬ì ì¸ **ìƒìœ„ í‚¤ì›Œë“œ**ì…ë‹ˆë‹¤. í•œë‘ ë‹¨ì–´ë¡œ êµ¬ì„±í•˜ë©° ë„ˆë¬´ êµ¬ì²´ì ì´ì§€ ì•Šê²Œ í•©ë‹ˆë‹¤. ì „êµ­ ë‹¨ìœ„ë¡œ ê²€ìƒ‰í•  ë²•í•œ **ê´‘ë²”ìœ„í•œ ì—…ì¢… ê´€ë ¨ ìš©ì–´**ë¥¼ ì„ íƒí•˜ì„¸ìš” (í•„ìš”ì— ë”°ë¼ specialtyë¥¼ í¬í•¨í•  ìˆ˜ ìˆìœ¼ë‚˜ ìƒëµ ê°€ëŠ¥).
  *ì˜ˆì‹œ*: ["ì¹´í˜"], ["ë‚´ê³¼"]

**ì¶”ê°€ ê·œì¹™**:
- ëª¨ë“  ë²”ì£¼ì˜ í‚¤ì›Œë“œì—ì„œ **specialty ëª©ë¡ì˜ ìµœì†Œ í•œ ê°€ì§€ íŠ¹ì„±**ì´ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. (íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ëŠ” **ë™ì˜ì–´ë‚˜ ìœ ì‚¬í•œ í‘œí˜„**ìœ¼ë¡œ ë°”ê¾¸ì–´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
- specialtyì— ì—†ëŠ” ë‹¤ë¥¸ ì „ë¬¸ë¶„ì•¼ë‚˜ íŠ¹ì„±ì€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€
- ì¶œë ¥ì€ **í•­ìƒ ìœ íš¨í•œ JSON ê°ì²´** í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ìš”êµ¬ëœ 4ê°œ í‚¤ë¥¼ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
- JSON ì™¸ì˜ ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

**ì¶œë ¥ ì˜ˆì‹œ** (category=ì¹´í˜, location=í™ëŒ€, specialty=ì• ê²¬ë™ë°˜, ë¸ŒëŸ°ì¹˜):
{{
  "longtail_keywords": [
    "í™ëŒ€ì— ìˆëŠ” ì• ê²¬ë™ë°˜ ë¸ŒëŸ°ì¹˜ ì¹´í˜ ì¶”ì²œí•´ì¤˜",
    "í™ëŒ€ ì• ê²¬ë™ë°˜ ì¹´í˜ ì¤‘ì— ë¸ŒëŸ°ì¹˜ ë§›ìˆëŠ” ê³³ì€?",
    "í™ëŒ€ ë¸ŒëŸ°ì¹˜ ê°€ëŠ¥í•œ ê°•ì•„ì§€ë™ë°˜ ì¹´í˜ ì–´ë”” ìˆì„ê¹Œ?",
    "í™ëŒ€ ì• ê²¬ ë™ë°˜ ì¹´í˜ ì°¾ì•„ë³´ê¸° (ë¸ŒëŸ°ì¹˜ ê°€ëŠ¥í•œ ê³³)",
    "í™ëŒ€ ë¸ŒëŸ°ì¹˜ ì¹´í˜ - ì• ê²¬ë™ë°˜ ë˜ëŠ”ë° ì–´ë””ê°€ ì¢‹ì§€?"
  ],
  "mid_keywords": [
    "í™ëŒ€ ì• ê²¬ë™ë°˜ ì¹´í˜",
    "í™ëŒ€ ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "í™ëŒ€ ì• ê²¬ ì¹´í˜ ë¸ŒëŸ°ì¹˜"
  ],
  "category_keywords": [
    "ë¸ŒëŸ°ì¹˜ ì¹´í˜",
    "ì• ê²¬ë™ë°˜ ì¹´í˜",
    "ì»¤í”¼ìˆ"
  ],
  "top_keywords": [
    "ì¹´í˜",
    "ì• ê²¬ ì¹´í˜"
  ]
}}"""

        return prompt

    def _parse_json_response(self, content: str) -> List[Dict]:
        """GPT ì‘ë‹µì—ì„œ JSON íŒŒì‹± (ìƒˆ í˜•ì‹ â†’ ê¸°ì¡´ level í˜•ì‹ ë³€í™˜)"""
        try:
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            data = json.loads(content.strip())

            # ìƒˆ í˜•ì‹ì¸ì§€ í™•ì¸ (longtail_keywords, mid_keywords ë“±ì˜ í‚¤ ì¡´ì¬)
            if isinstance(data, dict) and "longtail_keywords" in data:
                # ìƒˆ í˜•ì‹ â†’ ê¸°ì¡´ level í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                keywords = []

                # longtail_keywords â†’ Level 5
                for kw in data.get("longtail_keywords", []):
                    keywords.append({"keyword": kw, "level": 5, "reason": "ë¡±í…Œì¼ ê²€ìƒ‰ì–´"})

                # mid_keywords â†’ Level 4
                for kw in data.get("mid_keywords", []):
                    keywords.append({"keyword": kw, "level": 4, "reason": "ë‹ˆì¹˜ ê²€ìƒ‰ì–´"})

                # category_keywords â†’ Level 3
                for kw in data.get("category_keywords", []):
                    keywords.append({"keyword": kw, "level": 3, "reason": "ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ì–´"})

                # top_keywords â†’ Level 2, Level 1ë¡œ ë¶„í• 
                top_kws = data.get("top_keywords", [])
                if len(top_kws) >= 2:
                    keywords.append({"keyword": top_kws[0], "level": 2, "reason": "ìƒìœ„ ê²€ìƒ‰ì–´"})
                    keywords.append({"keyword": top_kws[1], "level": 1, "reason": "ìµœìƒìœ„ ê²€ìƒ‰ì–´"})
                elif len(top_kws) == 1:
                    keywords.append({"keyword": top_kws[0], "level": 2, "reason": "ìƒìœ„ ê²€ìƒ‰ì–´"})

                return keywords

            # ê¸°ì¡´ í˜•ì‹ (list of dicts with level)
            return data

        except Exception as e:
            print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def generate_related_keywords(
        self,
        category: str,
        specialty: Optional[str] = None
    ) -> Dict[str, List[str]]:
        """
        GPTë¥¼ ì‚¬ìš©í•œ ì—°ê´€ í‚¤ì›Œë“œ ìƒì„± (ì¡°í•©í•˜ì§€ ì•Šê³  ì—°ê´€ì–´ë§Œ)

        Args:
            category: ì—…ì¢… (ì˜ˆ: "ì¹´í˜", "ë³‘ì›")
            specialty: íŠ¹ì§•/ì „ë¬¸ë¶„ì•¼ (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: "ë¸ŒëŸ°ì¹˜, ì• ê²¬ë™ë°˜")

        Returns:
            ì—°ê´€ í‚¤ì›Œë“œ ë”•ì…”ë„ˆë¦¬
            {
                "category_related": ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"],
                "specialty1_related": ["ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ì•„ì¹¨ì‹ì‚¬", "ëª¨ë‹ì‹ì‚¬", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜ë©”ë‰´"],
                "specialty2_related": ["ë°˜ë ¤ë™ë¬¼", "ê°•ì•„ì§€ë™ë°˜", "í«í”„ë Œë“¤ë¦¬", "ì• ê²¬ì¹´í˜", "ë°˜ë ¤ê²¬"]
            }
        """
        if not self.client:
            return {}

        specialty_list = []
        if specialty:
            specialty_list = [s.strip() for s in specialty.split(',') if s.strip()]

        specialty_str = ', '.join(specialty_list) if specialty_list else "ì—†ìŒ"

        prompt = f"""ë‹¹ì‹ ì€ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê²€ìƒ‰ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì—…ì¢…ê³¼ íŠ¹ì„±ì— ëŒ€í•œ **ì—°ê´€ í‚¤ì›Œë“œ**ë§Œ ìƒì„±í•˜ì„¸ìš”. (ì¡°í•©í•˜ì§€ ë§ ê²ƒ!)

**ì…ë ¥:**
- category: {category}
- specialty: {specialty_str}

**ì¶œë ¥ í˜•ì‹**: JSON ê°ì²´ (ì½”ë“œë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSON)

**ê·œì¹™:**
1. categoryì— ëŒ€í•œ ì—°ê´€ í‚¤ì›Œë“œ 5ê°œ ìƒì„± â†’ "category_related" í‚¤
   - ë™ì˜ì–´, í•˜ìœ„ ì—…ì¢…, ìœ ì‚¬ ì—…ì¢… í¬í•¨
   - ì˜ˆ: category="ì¹´í˜" â†’ ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"]

2. specialtyê°€ ìˆìœ¼ë©´ ê° íŠ¹ì„±ë§ˆë‹¤ ì—°ê´€ í‚¤ì›Œë“œ 5ê°œì”© ìƒì„± â†’ "specialty1_related", "specialty2_related" ë“±ì˜ í‚¤
   - ë™ì˜ì–´, ê´€ë ¨ í‘œí˜„, ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ í¬í•¨
   - ì˜ˆ: specialty="ë¸ŒëŸ°ì¹˜" â†’ ["ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ì•„ì¹¨ì‹ì‚¬", "ëª¨ë‹ì‹ì‚¬", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜ë©”ë‰´"]
   - ì˜ˆ: specialty="ì• ê²¬ë™ë°˜" â†’ ["ë°˜ë ¤ë™ë¬¼", "ê°•ì•„ì§€ë™ë°˜", "í«í”„ë Œë“¤ë¦¬", "ì• ê²¬ì¹´í˜", "ë°˜ë ¤ê²¬"]

3. **ì¤‘ìš”**: ì¡°í•©í•˜ì§€ ë§ê³  ë‹¨ì¼ í‚¤ì›Œë“œë§Œ ìƒì„±í•  ê²ƒ!
   - âœ… Good: "ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ê°•ì•„ì§€ë™ë°˜"
   - âŒ Bad: "ë¸ŒëŸ°ì¹˜ ê°•ì•„ì§€ë™ë°˜ ì¹´í˜", "í™ëŒ€ ë¸ŒëŸ°ì¹˜"

**ì¶œë ¥ ì˜ˆì‹œ 1** (category=ì¹´í˜, specialty=ë¸ŒëŸ°ì¹˜, ì• ê²¬ë™ë°˜):
{{
  "category_related": ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"],
  "specialty1_related": ["ë¸ŒëŸ°ì¹˜ë§›ì§‘", "ì•„ì¹¨ì‹ì‚¬", "ëª¨ë‹ì‹ì‚¬", "ì¡°ì‹", "ë¸ŒëŸ°ì¹˜ë©”ë‰´"],
  "specialty2_related": ["ë°˜ë ¤ë™ë¬¼", "ê°•ì•„ì§€ë™ë°˜", "í«í”„ë Œë“¤ë¦¬", "ì• ê²¬ì¹´í˜", "ë°˜ë ¤ê²¬ë™ë°˜"]
}}

**ì¶œë ¥ ì˜ˆì‹œ 2** (category=ë³‘ì›, specialty=ì•ˆê³¼):
{{
  "category_related": ["ì˜ë£Œê¸°ê´€", "ì¢…í•©ë³‘ì›", "í´ë¦¬ë‹‰", "ì˜ì›", "ì§„ë£Œì†Œ"],
  "specialty1_related": ["ì•ˆê³¼ì˜ì›", "ëˆˆë³‘ì›", "ì‹œë ¥êµì •", "ë¼ì‹", "ì•ˆê³¼ì§„ë£Œ"]
}}

**ì¶œë ¥ ì˜ˆì‹œ 3** (category=ì¹´í˜, specialty ì—†ìŒ):
{{
  "category_related": ["ì»¤í”¼ìˆ", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜", "í‹°í•˜ìš°ìŠ¤", "ë¶ì¹´í˜"]
}}

ì´ì œ ì…ë ¥ëœ ì •ë³´ë¡œ ì—°ê´€ í‚¤ì›Œë“œë¥¼ ìƒì„±í•˜ì„¸ìš”:"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a Naver Place SEO expert. Always respond in Korean with valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )

            content = response.choices[0].message.content

            # ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]

            related_keywords = json.loads(content.strip())
            return related_keywords

        except Exception as e:
            print(f"ì—°ê´€ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}

    def validate_specialty_inclusion(
        self,
        keywords: List[Dict],
        specialty: Optional[str]
    ) -> List[Dict]:
        """
        specialtyê°€ ì œê³µëœ ê²½ìš° í‚¤ì›Œë“œì— í¬í•¨ ì—¬ë¶€ ê²€ì¦ (ë‹¨ê³„ì  ê¸°ì¤€)

        Args:
            keywords: ìƒì„±ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            specialty: íŠ¹ì§•/ì „ë¬¸ë¶„ì•¼

        Returns:
            ê²€ì¦ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ê²½ê³  í¬í•¨)
        """
        if not specialty:
            return keywords

        specialty_list = [s.strip() for s in specialty.split(',') if s.strip()]
        if not specialty_list:
            return keywords

        # Levelë³„ specialty í¬í•¨ ì¹´ìš´íŠ¸
        level_stats = {1: {"total": 0, "with_specialty": 0},
                       2: {"total": 0, "with_specialty": 0},
                       3: {"total": 0, "with_specialty": 0},
                       4: {"total": 0, "with_specialty": 0},
                       5: {"total": 0, "with_specialty": 0}}

        validated = []
        for kw in keywords:
            keyword_text = kw.get('keyword', '')
            level = kw.get('level', 5)

            # specialty í¬í•¨ ì—¬ë¶€ í™•ì¸
            has_specialty = any(spec.lower() in keyword_text.lower() for spec in specialty_list)

            level_stats[level]["total"] += 1
            if has_specialty:
                level_stats[level]["with_specialty"] += 1

            # Level 1-2ëŠ” 100% í•„ìˆ˜
            if not has_specialty and level <= 2:
                print(f"âš ï¸ [CRITICAL] Level {level} í‚¤ì›Œë“œ '{keyword_text}'ì— íŠ¹ì§•({', '.join(specialty_list)}) ëˆ„ë½ (í•„ìˆ˜!)")

            validated.append(kw)

        # Levelë³„ í¬í•¨ë¥  ê²€ì¦
        thresholds = {1: 1.0, 2: 1.0, 3: 0.8, 4: 0.7, 5: 0.6}
        for level, stats in level_stats.items():
            if stats["total"] > 0:
                rate = stats["with_specialty"] / stats["total"]
                threshold = thresholds[level]
                if rate < threshold:
                    print(f"âš ï¸ Level {level} specialty í¬í•¨ë¥ : {rate:.1%} (ëª©í‘œ: {threshold:.0%}) - {stats['with_specialty']}/{stats['total']}ê°œ")

        return validated
